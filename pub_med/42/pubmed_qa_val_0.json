{
    "pubmed_qa": {
        "pubmed_qa": {
            "25499207": {
                "source": [
                    "\"Current evidence suggests that neck pain is negatively associated with health-related quality of life (HRQoL). However, these studies are cross-sectional and do not inform the association between neck pain and future HRQoL.\nThe purpose of this study was to investigate the association between increasing grades of neck pain severity and HRQoL 6 months later. In addition, this longitudinal study examines the crude association between the course of neck pain and HRQoL.\nThis is a population-based cohort study.\nEleven hundred randomly sampled Saskatchewan adults were included.\nOutcome measures were the mental component summary (MCS) and physical component summary (PCS) of the Short-Form-36 (SF-36) questionnaire.\nWe formed a cohort of 1,100 randomly sampled Saskatchewan adults in September 1995. We used the Chronic Pain Questionnaire to measure neck pain and its related disability. The SF-36 questionnaire was used to measure physical and mental HRQoL 6 months later. Multivariable linear regression was used to measure the association between graded neck pain and HRQoL while controlling for confounding. Analysis of variance and t tests were used to measure the crude association among four possible courses of neck pain and HRQoL at 6 months. The neck pain trajectories over 6 months were no or mild neck pain, improving neck pain, worsening neck pain, and persistent neck pain. Finally, analysis of variance was used to examine changes in baseline to 6-month PCS and MCS scores among the four neck pain trajectory groups.\nThe 6-month follow-up rate was 74.9%. We found an exposure-response relationship between neck pain and physical HRQoL after adjusting for age, education, arthritis, low back pain, and depressive symptomatology. Compared with participants without neck pain at baseline, those with mild (\u03b2=-1.53, 95% confidence interval [CI]=-2.83, -0.24), intense (\u03b2=-3.60, 95% CI=-5.76, -1.44), or disabling (\u03b2=-8.55, 95% CI=-11.68, -5.42) neck pain had worse physical HRQoL 6 months later. We did not find an association between neck pain and mental HRQoL. A worsening course of neck pain and persistent neck pain were associated with worse physical HRQoL.\"\nQuestion:\n\"Is neck pain associated with worse health-related quality of life 6 months later?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26452334": {
                "source": [
                    "\"The aim of this study was to assess the reproducibility of different measurement methods and define the most workable technique for measuring head and neck paragangliomas, to determine the best method for evaluating tumour growth. The evaluation of tumour growth is vital for a 'wait-and-scan' policy, a management strategy that became increasingly important.\nMethod comparison study.\nThirty tumours, including carotid body, vagal body, jugulotympanic tumours and conglomerates of multiple tumours, were measured in duplicate, using linear dimensions, manual area tracing and an automated segmentation method.\nReproducibility was assessed using the Bland-Altman method.\nThe smallest detectable difference using the linear dimension method was 11% for carotid body and 27% for vagal body tumours, compared with 17% and 20% for the manual area tracing method. Due to the irregular shape of paragangliomas in the temporal bone and conglomerates, the manual area tracing method showed better results in these tumours (26% and 8% versus 54% and 47%). The linear dimension method was significantly faster (median 4.27 versus 18.46 minutes, P<0.001). The automatic segmentation method yielded smallest detectable differences between 39% and 75%, and although fast (2.19 \u00b1 1.49 minutes), it failed technically.\"\nQuestion:\n\"Measurement of head and neck paragangliomas: is volumetric analysis worth the effort?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "14631523": {
                "source": [
                    "\"The objectives were to identify prognostic factors for the survival of children with cerebellar astrocytoma, and to evaluate the reproducibility and prognostic value of histological sub-classification and grading.\nChildren aged 0-14 years treated in Denmark for a cerebellar astrocytoma in the period 1960-1984 were included and followed until January 2001 or until their death. The histological specimens from each patient were reviewed for revised grading and classification according to three different classification schemes: the WHO, the Kernohan and the Daumas-Duport grading systems.\nThe overall survival rate was 81% after a follow-up time of 15-40 years. The significant positive prognostic factors for survival were \"surgically gross-total removal\" of the tumour at surgery and location of the tumour in the cerebellum proper as opposed to location in the fourth ventricle. No difference in survival time was demonstrated when we compared pilocytic astrocytoma and fibrillary astrocytoma. Moreover, we found that the Kernohan and the WHO classification systems had no predictive value and that the Daumas-Duport system is unsuitable as a prognostic tool for low-grade posterior fossa astrocytomas.\"\nQuestion:\n\"Sub-classification of low-grade cerebellar astrocytoma: is it clinically meaningful?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "8916748": {
                "source": [
                    "\"To assess the risk of death associated with work based and non-work based measures of socioeconomic status before and after retirement age.\nFollow up study of mortality in relation to employment grade and car ownership over 25 years.\nThe first Whitehall study.\n18,133 male civil servants aged 40-69 years who attended a screening examination between 1967 and 1970.\nDeath.\nGrade of employment was a strong predictor of mortality before retirement. For men dying at ages 40-64 the lowest employment grade had 3.12 times the mortality of the highest grade (95% confidence interval 2.4 to 4.1). After retirement the ability of grade to predict mortality declined (rate ratio 1.86; 1.6 to 2.2). A non-work based measure of socioeconomic status (car ownership) predicted mortality less well than employment grade before retirement but its ability to predict mortality declined less after retirement. Using a relative index of inequality that was sensitive to the distribution among socioeconomic groups showed employment grade and car ownership to have independent associations with mortality that were of equal magnitude after retirement. The absolute difference in death rates between the lowest and highest employment grades increased with age from 12.9 per 1000 person years at ages 40-64 to 38.3 per 1000 at ages 70-89.\"\nQuestion:\n\"Do socioeconomic differences in mortality persist after retirement?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "23048048": {
                "source": [
                    "\"This study examined the extent to which ADHD was associated with risky sexual behaviors (RSBs) in a sample of 92 undergraduates with (n = 44) and without (n = 48) ADHD. Mother-child relationship quality was examined as a potential moderator.\nWe conducted comprehensive assessments for ADHD and comorbid conditions and collected measures of RSB and mother-child relationship quality.\nFemale students with ADHD were least likely to use condoms than males overall and females without ADHD. An interaction between ADHD and mother-child relationship quality accounted for significant variance in the number of past-year sexual partners, such that a high-quality relationship was protective only for students with ADHD. No other significant associations were found between ADHD and RSB.\"\nQuestion:\n\"Risky sexual behavior among college students With ADHD: is the mother-child relationship protective?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "12607666": {
                "source": [
                    "\"The aim of this study was to evaluate the effectiveness of our surgical strategy for acute aortic dissection based on the extent of the dissection and the site of the entry, with special emphasis on resection of all dissected aortic segments if technically possible.\nBetween January 1995 and March 2001, 43 consecutive patients underwent operations for acute aortic dissection. In all patients the distal repair was performed under circulatory arrest without the use of an aortic cross-clamp. Fifteen patients underwent aortic arch replacement with additional reconstruction of supra-aortic vessels in 3 patients. Complete replacement of all dissected tissue could be achieved in 21 patients (group 1). Because of the distal extent of the dissection beyond the aortic arch, replacement of all the dissected tissue was not possible in 22 patients (group 2).\nEarly mortality was 4.7% (2 patients), and the incidence of perioperative cerebrovascular events was 7.0% (3 patients). All of these events occurred in group 2 (p<0.025). During the follow-up period of 6 years or less, 5 patients died, all from causes not related to the aorta or the aortic valve. A persisting patent false lumen was observed in 14 of the 36 surviving patients (39%).\"\nQuestion:\n\"Is extended aortic replacement in acute type A dissection justifiable?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26708803": {
                "source": [
                    "\"Treatment of neonatal testicular torsion has two objectives: salvage of the involved testicle (which is rarely achieved) and preservation of the contralateral gonad. The second goal universally involves contralateral testicular scrotal fixation to prevent the future occurrence of contralateral torsion. However, there is controversy with regards to management of a synchronous contralateral hydrocele. It has been our policy not to address the contralateral hydrocele through an inguinal incision to minimize potential injury to the spermatic cord. Our objective in this study was to determine whether the decision to manage a contralateral hydrocele in cases of neonatal testicular torsion solely through a scrotal approach is safe and effective.\nWe reviewed all cases of neonatal testicular torsion occurring at our institution between the years 1999 and 2006. Age at presentation, physical examination, ultrasonographic and intraoperative findings were recorded. Patients were followed after initial surgical intervention to determine the likelihood of developing a subsequent hydrocele or hernia.\nThirty-seven patients were identified as presenting with neonatal torsion. Age of presentation averaged 3.5 days (range 1-14 days). Left-sided pathology was seen more commonly than the right, with a 25:12 distribution. All torsed testicles were nonviable. Twenty-two patients were noted to have a contralateral hydrocele at presentation. All hydroceles were opened through a scrotal approach at the time of contralateral scrotal fixation. No patient underwent an inguinal exploration to examine for a patent process vaginalis. None of the patients who presented with a hydrocele have developed a clinical hydrocele or hernia after an average 7.5 years (range 4.3-11.2) follow-up.\"\nQuestion:\n\"Treatment of contralateral hydrocele in neonatal testicular torsion: Is less more?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "23361217": {
                "source": [
                    "\"There are a number of factors responsible for the longevity of unicompartmental knee replacements (UKR). These include the magnitude of postoperative alignment and the type of material used. The effect of component design and material on postoperative alignment, however, has not been explored.\nWe retrospectively reviewed 89 patients who underwent UKR with robotic guidance. Patients were divided into two groups, according to whether they had received an all-polyethylene inlay component (Inlay group) or a metal-backed onlay component (Onlay group). We explored the magnitude of mechanical alignment correction obtained in both groups.\nMean postoperative mechanical alignment was significantly closer to neutral in the Onlay group (mean=2.8\u00b0; 95% CI=2.4\u00b0, 3.2\u00b0) compared to the Inlay group (mean=3.9\u00b0; 95% CI=3.4\u00b0, 4.4\u00b0) (R2=0.65; P=0.003), adjusting for gender, BMI, age, side and preoperative mechanical alignment (Fig. 2). Further exploration revealed that the thickness of the tibial polyethyelene insert had a significant effect on postoperative alignment when added to the model (R2=0.68; P=0.01).\"\nQuestion:\n\"Does the type of tibial component affect mechanical alignment in unicompartmental knee replacement?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "19130332": {
                "source": [
                    "\"Uncontrolled hemorrhage is the leading cause of fatality. The aim of this study was to evaluate the effect of zeolite mineral (QuikClot - Advanced Clotting Sponge [QC-ACS]) on blood loss and physiological variables in a swine extremity arterial injury model.\nSixteen swine were used. Oblique groin incision was created and a 5 mm incision was made. The animals were allocated to: control group (n: 6): Pressure dressing was applied with manual pressure over gauze sponge; or QC group (n: 10): QC was directly applied over lacerated femoral artery. Mean arterial pressure, blood loss and physiological parameters were measured during the study period.\nApplication of QC led to a slower drop in blood pressure. The control group had a significantly higher increase in lactate within 60 minutes. The mean prothrombin time in the control group was significantly increased at 60 minutes. The application of QC led to decreased total blood loss. The QC group had significantly higher hematocrit levels. QC application generated a significant heat production. There were mild edematous and vacuolar changes in nerve samples.\"\nQuestion:\n\"Is the zeolite hemostatic agent beneficial in reducing blood loss during arterial injury?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "25604390": {
                "source": [
                    "\"Dickkopf-3 (DKK3) may act as a tumor suppressor as it is down-regulated in various types of cancer. This study assessed the DKK3 protein expression in gastric cancer and its potential value as a prognostic marker.\nDKK3 expression was evaluated by immunohistochemistry in 158 gastric cancer samples from patients who underwent gastrectomy from 2002 to 2008. Clinicopathological parameters and survival data were analyzed.\nLoss of DKK3 expression was found in 64 of 158 (40.5%) samples, and it was associated with advanced T stage (p<0.001), lymph node metastasis (p<0.001), UICC TNM stage (p<0.001), tumor location (p = 0.029), lymphovascular invasion (p = 0.035), and perineural invasion (p = 0.032). Patients without DKK3 expression in tumor cells had a significantly worse disease-free and overall survival than those with DKK3 expression (p<0.001, and p = 0.001, respectively). TNM stage (p = 0.028 and p<0.001, respectively) and residual tumor (p<0.001 and p = 0.003, respectively) were independent predictors of disease-free and overall survival. Based on the preoperative clinical stage assessed by computed tomography (CT), loss of DKK3 expression was predominantly associated with worse prognosis in patients with clinically node-negative advanced gastric cancer (AGC). The combination of DKK3 expression status and CT increased the accuracy of CT staging for predicting lymph node involvement from 71.5 to 80.0% in AGC patients.\"\nQuestion:\n\"Aberrant loss of dickkopf-3 in gastric cancer: can it predict lymph node metastasis preoperatively?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "16296668": {
                "source": [
                    "\"To investigate the ability of a bedside swallowing assessment to reliably exclude aspiration following acute stroke.\nConsecutive patients admitted within 24 h of stroke onset to two hospitals.\nA prospective study. Where possible, all patients had their ability to swallow assessed on the day of admission by both a doctor and a speech and language therapist using a standardized proforma. A videofluoroscopy examination was conducted within 3 days of admission.\n94 patients underwent videofluoroscopy; 20 (21%) were seen to be aspirating, although this was not detected at the bedside in 10. In 18 (22%) of the patients the speech and language therapist considered the swallow to be unsafe. In the medical assessment, 39 patients (41%) had an unsafe swallow. Bedside assessment by a speech and language therapist gave a sensitivity of 47%, a specificity of 86%, positive predictive value (PPV) of 50% and a negative predictive value (NPV) of 85% for the presence of aspiration. Multiple logistic regression was used to identify the optimum elements of the bedside assessments for predicting the presence of aspiration. A weak voluntary cough and any alteration in conscious level gave a sensitivity of 75%, specificity of 72%, PPV of 41% and NPV of 91% for aspiration.\"\nQuestion:\n\"Can bedside assessment reliably exclude aspiration following acute stroke?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "21084567": {
                "source": [
                    "\"Home blood pressure (BP) monitoring is gaining increasing popularity among patients and may be useful in hypertension management. Little is known about the reliability of stroke patients' records of home BP monitoring.\nTo assess the reliability of home BP recording in hypertensive patients who had suffered a recent stroke or transient ischaemic attack.\nThirty-nine stroke patients (mean age 73 years) randomized to the intervention arm of a trial of home BP monitoring were included. Following instruction by a research nurse, patients recorded their BPs at home and documented them in a booklet over the next year. The booklet readings over a month were compared with the actual readings downloaded from the BP monitor and were checked for errors or selective bias in recording.\nA total of 1027 monitor and 716 booklet readings were recorded. Ninety per cent of booklet recordings were exactly the same as the BP monitor readings. Average booklet readings were 0.6 mmHg systolic [95% confidence interval (95% CI) -0.6 to 1.8] and 0.3 mmHg diastolic (95% CI -0.3 to 0.8) lower than those on the monitor.\"\nQuestion:\n\"Are stroke patients' reports of home blood pressure readings reliable?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "21558951": {
                "source": [
                    "\"To ascertain whether level of intrauterine cocaine exposure (IUCE) is associated with early adolescent delinquent behavior, after accounting for prenatal exposures to other psychoactive substances and relevant psychosocial factors.\nNinety-three early adolescents (12.5-14.5 years old) participating since birth in a longitudinal study of IUCE reported delinquent acts via an audio computer-assisted self-interview. Level of IUCE and exposure to cigarettes, alcohol, and marijuana were determined by maternal report, maternal and infant urine assays, and infant meconium assays at birth. Participants reported their exposure to violence on the Violence Exposure Scale for Children-Revised at ages 8.5, 9.5, and 11 years and during early adolescence, and the strictness of supervision by their caregivers during early adolescence.\nOf the 93 participants, 24 (26%) reported \u2265 3 delinquent behaviors during early adolescence. In the final multivariate model (including level of IUCE and cigarette exposure, childhood exposure to violence, and caregiver strictness/supervision) \u2265 3 delinquent behaviors were not significantly associated with level of IUCE but were significantly associated with intrauterine exposure to half a pack or more of cigarettes per day and higher levels of childhood exposure to violence, effects substantially unchanged after control for early adolescent violence exposure.\"\nQuestion:\n\"Are there effects of intrauterine cocaine exposure on delinquency during early adolescence?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "25034219": {
                "source": [
                    "\"Obese children and adolescents referred to the pediatric endocrinology department were enrolled consecutively. Height and weight of all children and their mothers were measured. Maternal feeding practices were measured using an adapted version of the Child Feeding Questionnaire (CFQ). Answers were compared between obese (Body Mass Index [BMI] \u2265 30 kg/m2) and non-obese mothers.\nA total of 491 obese subjects (292 girls, mean age 12.0 \u00b1 2.8 years) and their mothers participated in this study. A direct correlation between children's BMI and their mothers' BMI was found (P<0.001) both in girls (r = 0.372) and boys (r = 0.337). While 64.4% of mothers were found obese in the study, only half of them consider themselves as obese. No difference were found in the scores of the subscales \"perceived responsibility\", \"restriction\", \"concern for child's weight\" and \"monitoring\" between obese and non-obese mothers. Child's BMI-SDS positively correlated with mothers' personal weight perception, concern for child's weight and restriction after adjustment for child's age (P<0.001, P = 0.012 and P = 0.002, respectively).\"\nQuestion:\n\"Does maternal obesity have an influence on feeding behavior of obese children?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26701174": {
                "source": [
                    "\"To ascertain whether hospital type is associated with differences in total cost and outcomes for inpatient tonsillectomy.\nCross-sectional analysis of the 2006, 2009, and 2012 Kids' Inpatient Database (KID).\nChildren \u226418 years of age undergoing tonsillectomy with/without adenoidectomy were included. Risk-adjusted generalized linear models assessed for differences in hospital cost and length of stay (LOS) among children managed by (1) non-children's teaching hospitals (NCTHs), (2) children's teaching hospitals (CTHs), and (3) nonteaching hospitals (NTHs). Risk-adjusted logistic regression compared the odds of major perioperative complications (hemorrhage, respiratory failure, death). Models accounted for clustering of patients within hospitals, were weighted to provide national estimates, and controlled for comorbidities.\nThe 25,685 tonsillectomies recorded in the KID yielded a national estimate of 40,591 inpatient tonsillectomies performed in 2006, 2009, and 2012. The CTHs had significantly higher risk-adjusted total cost and LOS per tonsillectomy compared with NCTHs and NTHs ($9423.34/2.8 days, $6250.78/2.11 days, and $5905.10/2.08 days, respectively; P<.001). The CTHs had higher odds of complications compared with NCTHs (odds ratio [OR], 1.48; 95% CI, 1.15-1.91; P = .002) but not when compared with NTHs (OR, 1.19; 95% CI, 0.89-1.59; P = .23). The CTHs were significantly more likely to care for patients with comorbidities (P<.001).\"\nQuestion:\n\"Inpatient Pediatric Tonsillectomy: Does Hospital Type Affect Cost and Outcomes of Care?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "10135926": {
                "source": [
                    "\"Patients transported by helicopter often require advanced airway management. The purpose of this study was to determine whether or not the in-flight environment of air medical transport in a BO-105 helicopter impairs the ability of flight nurses to perform oral endotracheal intubation.\nThe study was conducted in an MBB BO-105 helicopter.\nFlight nurses performed three manikin intubations in each of the two study environments: on an emergency department stretcher and in-flight in the BO-105 helicopter.\nThe mean time required for in-flight intubation (25.9 +/- 10.9 seconds) was significantly longer than the corresponding time (13.2 +/- 2.8 seconds) required for intubation in the control setting (ANOVA, F = 38.7, p<.001). All intubations performed in the control setting were placed correctly in the trachea; there were two (6.7%) esophageal intubations in the in-flight setting. The difference in appropriate endotracheal intubation between the two settings was not significant (chi 2 = 0.3; p>0.05).\"\nQuestion:\n\"Is oral endotracheal intubation efficacy impaired in the helicopter environment?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "21880023": {
                "source": [
                    "\"To study whether exercise during pregnancy reduces the risk of postnatal depression.\nRandomized controlled trial.\nTrondheim and Stavanger University Hospitals, Norway.\nEight hundred and fifty-five pregnant women were randomized to intervention or control groups.\nThe intervention was a 12 week exercise program, including aerobic and strengthening exercises, conducted between week 20 and 36 of pregnancy. One weekly group session was led by physiotherapists, and home exercises were encouraged twice a week. Control women received regular antenatal care.\nEdinburgh Postnatal Depression Scale (EPDS) completed three months after birth. Scores of 10 or more and 13 or more suggested probable minor and major depression, respectively.\nFourteen of 379 (3.7%) women in the intervention group and 17 of 340 (5.0%) in the control group had an EPDS score of \u226510 (p=0.46), and four of 379 (1.2%) women in the intervention group and eight of 340 (2.4%) in the control group had an EPDS score of \u226513 (p=0.25). Among women who did not exercise prior to pregnancy, two of 100 (2.0%) women in the intervention group and nine of 95 (9.5%) in the control group had an EPDS score of \u226510 (p=0.03).\"\nQuestion:\n\"Does exercise during pregnancy prevent postnatal depression?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26133538": {
                "source": [
                    "\"Abdominal bloating is reported by a majority of irritable bowel syndrome (IBS) patients. Excess colonic fermentation may cause gaseous symptoms. Several foodstuffs contain oligosaccharides with an \u03b1-galactosidic linkage that is resistant to mammalian hydrolases. Assisted hydrolysis by exogenous \u03b1-galactosidase enzyme (AG) could offer a way of controlling IBS symptoms by reducing colonic fermentation and gas production. The aim of this study was to assess the effect of AG on symptom severity and quality of life in IBS patients with abdominal bloating or flatulence.\nA total of 125 subjects with IBS received AG or placebo at meals for 12 weeks. IBS-Symptom Severity Score (IBS-SSS) and quality of life (QoL) were assessed at baseline, during the treatment and at 4-week follow-up.\nAG showed a trend toward a more prominent decrease in IBS-SSS. The responder rate at week 16 was higher for the AG group. No difference was detected in QoL between AG and placebo groups. A total of 25 patients (18 in AG group and 7 in placebo group, p = 0.016) withdrew from the study. Abdominal pain and diarrhea were more often reported as reason for withdrawal in AG group.\"\nQuestion:\n\"Does oral \u03b1-galactosidase relieve irritable bowel symptoms?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "25699562": {
                "source": [
                    "\"Our previous work demonstrated that the Transmissible Liability Index (TLI), an instrument designed as an index of liability for substance use disorder (SUD), is associated with risk of substance use disorder. This longitudinal study assessed whether TLI measured in 10-12-year-olds (late childhood) predicts suicidal behavior from age 12-14 (preadolescence) to age 25 (young adulthood). We hypothesized that TLI would predict number and severity of suicide attempts.\nSubjects were sons of men who had lifetime history of SUD (n\u2009=\u2009250), called the High Average Risk (HAR) group, and sons of men with no lifetime history of a SUD (n\u2009=\u2009250), called the Low Average Risk (LAR) group. The TLI was delineated at baseline (age 10-12), and age-specific versions were administered at 12-14, 16, 19, 22, and 25 years of age.\nTLI was significantly associated with number and severity of lifetime suicide attempts.\"\nQuestion:\n\"Does the Transmissible Liability Index (TLI) assessed in late childhood predict suicidal symptoms at young adulthood?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "18714572": {
                "source": [
                    "\"Vaginal intraepithelial neoplasia is a little known disease which could be related to risk factors different from simple HPV infections.\nTo ascertain wheter vaginal lesions have a natural history similar to cervical lesions.MATERIALS &\nA retrospective study to identify patients with vaginal lesions and synchronous cervical lesions through biopsy. The rate of mild cervical lesions (koilocytosis, warts, CIN I with and without koilocytosis) was compared with the rate of severe cervical lesions (CIN II and III, cervical carcinoma) in patients with mild vaginal lesions (warts and koilocytosis, and low-grade VAIN) and in patients with severe vaginal lesions (high-grade VAIN). Using koilocytosis as a marker, the rate of \"active\" cervical lesions was compared with the rate of \"non active\" cervical lesions in patients with \"active\" versus \"non active\" vaginal lesions. Finally, the rates of mild and severe cervical lesions were compared among each group of VAIN (low-grade, high-grade, with or without koilocytosis).\nIn patients with mild vaginal lesions, mild cervical lesions were significantly more frequent than severe cervical lesions. In patients with \"active\" vaginal lesions the rate of \"active\" cervical lesions was significantly higher than \"non active\" cervical lesions. The differences in rates of mild cervical lesions and severe cervical lesions among patients with high-grade VAIN and low-grade VAIN (with and without koilocytosis) were not significant.\"\nQuestion:\n\"Does vaginal intraepithelial neoplasia have the same evolution as cervical intraepithelial neoplasia?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "22513023": {
                "source": [
                    "\"To assess whether Indigenous Australians age prematurely compared with other Australians, as implied by Australian Government aged care policy, which uses age 50 years and over for population-based planning for Indigenous people compared with 70 years for non-indigenous people.\nCross-sectional analysis of aged care assessment, hospital and health survey data comparing Indigenous and non-indigenous age-specific prevalence of health conditions. Analysis of life tables for Indigenous and non-indigenous populations comparing life expectancy at different ages.\nAt age 63 for women and age 65 for men, Indigenous people had the same life expectancy as non-indigenous people at age 70. There is no consistent pattern of a 20-year lead in age-specific prevalence of age-associated conditions for Indigenous compared with other Australians. There is high prevalence from middle-age onwards of some conditions, particularly diabetes (type unspecified), but there is little or no lead for others.\"\nQuestion:\n\"Do Indigenous Australians age prematurely?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "21459725": {
                "source": [
                    "\"Xanthogranulomatous cholecystitis (XGC) is an uncommon variant of chronic cholecystitis, characterized by marked thickening of the gallbladder wall and dense local adhesions. It often mimics a gallbladder carcinoma (GBC), and may coexist with GBC, leading to a diagnostic dilemma. Furthermore, the premalignant nature of this entity is not known. This study was undertaken to assess the p53, PCNA and beta-catenin expression in XGC in comparison to GBC and chronic inflammation.\nSections from paraffin-embedded blocks of surgically resected specimens of GBC (69 cases), XGC (65), chronic cholecystitis (18) and control gallbladder (10) were stained with the monoclonal antibodies to p53 and PCNA, and a polyclonal antibody to beta-catenin. p53 expression was scored as the percentage of nuclei stained. PCNA expression was scored as the product of the percentage of nuclei stained and the intensity of the staining (1-3). A cut-off value of 80 for this score was taken as a positive result. Beta-catenin expression was scored as type of expression-membranous, cytoplasmic or nuclear staining.\np53 mutation was positive in 52% of GBC cases and 3% of XGC, but was not expressed in chronic cholecystitis and control gallbladders. p53 expression was lower in XGC than in GBC (P<0.0001). PCNA expression was seen in 65% of GBC cases and 11% of XGC, but not in chronic cholecystitis and control gallbladders. PCNA expression was higher in GBC than XGC (P=0.0001), but there was no significant difference between the XGC, chronic cholecystitis and control gallbladder groups. Beta-catenin expression was positive in the GBC, XGC, chronic cholecystitis and control gallbladder groups. But the expression pattern in XGC, chronic cholecystitis and control gallbladders was homogenously membranous, whereas in GBC the membranous expression pattern was altered to cytoplasmic and nuclear.\"\nQuestion:\n\"Xanthogranulomatous cholecystitis: a premalignant condition?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "19302863": {
                "source": [
                    "\"The present study aims to compare strength, healing, and operation time of experimental intestinal anastomoses performed by polyglactin 910 (Vicryl; Ethicon, Edinburgh, United Kingdom) sutures with ethyl-2-cyanoacrylate glue (Pattex; Henkel, Dusseldorf, Germany).\nNinety-six Sprague-Dawley rats were divided into 2 (groups E and L). Each group was further subdivided into 6 subgroups (EA1, EA2, EA3, EB1, EB2, EB3, LA1, LA2, LA3, LB1, LB2, LB3), each containing 8 rats. Intestinal anastomosis was performed by polyglactin 910 sutures in A subgroups and with ethyl-2-cyanoacrylate in B subgroups. The anastomosis was end to end in A1 and B1, side to side in A2 and B2, and end to side in A3 and B3. Time for anastomosis performance (AT) was recorded. In group E, bursting pressures and hydroxyproline levels were determined on the second postoperative day, whereas in group L, the same measurements were made on the sixth postoperative day. One-way analysis of variance was used for analyses of variance in the groups. Quantitative data were analyzed with Student's t test. P value was considered significant at less than .05.\nThere was no significant difference between bursting pressures of subgroup pairs on both postoperative days 2 and 6. Hydroxyproline levels and AT were significantly better in B subgroups.\"\nQuestion:\n\"Is the use of cyanoacrylate in intestinal anastomosis a good and reliable alternative?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "24434052": {
                "source": [
                    "\"The last 20 years has seen a marked improvement in skin cancer awareness campaigns. We sought to establish whether this has affected the presenting Breslow thickness of malignant melanoma in the South West.\nThis is a retrospective study looking at the first presentation of melanomas from 2003 to 2011. Data was accessed using the local online melanoma database.\nA total of 2001 new melanomas presented from 2003 to 2012 (Male:Female = 1:1.062). The average yearly number of melanomas was 200.1 (range = 138-312). The mean age was 62.5 years (range 12-99). Data was analysed using a Chi\u00b2 test. For 0-1 mm melanomas, there is a significant difference in the observed versus expected values over the 10 years (p = 0.0018). There is an increasing proportion of 0-1 mm (thin) melanomas presenting year on year, with a positive linear trend. This is very statistically significant (p<0.0001). The 1-2 mm melanomas are decreasing in proportion with a negative linear trend (p = 0.0013). The 2-4 mm are also decreasing in proportion (p = 0.0253). There is no significant change in the thick>4 mm melanomas (p = 0.1456).\"\nQuestion:\n\"Are we seeing the effects of public awareness campaigns?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "19103915": {
                "source": [
                    "\"There is an urgent need to increase opportunistic screening for sexually transmitted infections (STIs) in community settings, particularly for those who are at increased risk including men who have sex with men (MSM). The aim of this qualitative study was to explore whether home sampling kits (HSK) for multiple bacterial STIs are potentially acceptable among MSM and to identify any concerns regarding their use. This study was developed as part of a formative evaluation of HSKs.\nFocus groups and one-to-one semi-structured interviews with MSM were conducted. Focus group participants (n = 20) were shown a variety of self-sampling materials and asked to discuss them. Individual interviewees (n = 24) had experience of the self-sampling techniques as part of a pilot clinical study. All data were digitally recorded and transcribed verbatim. Data were analysed using a framework analysis approach.\nThe concept of a HSK was generally viewed as positive, with many benefits identified relating to increased access to testing, enhanced personal comfort and empowerment. Concerns about the accuracy of the test, delays in receiving the results, the possible lack of support and potential negative impact on 'others' were raised.\"\nQuestion:\n\"Are home sampling kits for sexually transmitted infections acceptable among men who have sex with men?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "22211919": {
                "source": [
                    "\"Urine samples were examined by wet smear microscopy, incubated in 5% CO(2) for 1-2 days, and species-specific real-time polymerase chain reaction (PCR) for A. schaalii was performed.\nIn 5 of the 29 screened urines, A. schaalii was found only by real-time PCR in quantities equivalent to \u2265 10(4) -10(5) CFU/mL. In addition, A. schaalii was found in quantities equivalent to \u2265 10(6) CFU/mL by both culture and PCR in two children with a urinary tract infection and large numbers of leucocytes in the urine.\"\nQuestion:\n\"Actinobaculum schaalii, a cause of urinary tract infections in children?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "10757151": {
                "source": [
                    "\"Ischemic preconditioning (IP) is initiated through one or several short bouts of ischemia and reperfusion which precede a prolonged ischemia. To test whether a reperfusion must precede the prolonged index ischemia, a series without reperfusion (intraischemic preconditioning: IIP) and a series with gradual onset of ischemia, i.e. ramp ischemia (RI), which is possibly related to the development of hibernation, was compared to conventional IP (CIP).\nExperiments were performed an 27 blood-perfused rabbit hearts (Langendorff apparatus) that were randomized into one of four series: (1) control (n = 7): 60 min normal flow - 60 min low flow (10%) ischemia - 60 min reperfusion. (2) CIP (n = 7): 4 times 5 min zero flow with 10 min reperfusion each - 60 min low flow (10%) - ischemia 60 min reperfusion. (3) IIP (n = 7): 50 min normal flow - 10 min no flow - 60min low flow (10%) ischemia -4 60min reperfusion. (4) RI (n=6): gradual reduction to 10% flow during 60min - 60min low flow (10%) ischemia - 60min reperfusion. At the end of each protocol, the infarcted area was assessed.\nThe infarct area in control hearts was 6.7+/-1.4% (means+/-SEM) of LV total area, in CIP hearts 2.6+/-0.8%, in IIP hearts 3.1+/-0.5%, and in RI hearts 3.0+/-0.3% (all p<0.05 vs. control). The differences between the three protection protocols were statistically not significant, and no protective protocol reduced post-ischemic myocardial dysfunction.\"\nQuestion:\n\"Does ischemic preconditioning require reperfusion before index ischemia?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "25957366": {
                "source": [
                    "\"Electronic health records have the potential to facilitate family history use by primary care physicians (PCPs) to provide personalized care. The objective of this study was to determine whether automated, at-the-visit tailored prompts about family history risk change PCP behavior.\nAutomated, tailored prompts highlighting familial risk for heart disease, stroke, diabetes, and breast, colorectal, or ovarian cancer were implemented during 2011 to 2012. Medical records of a cohort of community-based primary care patients, aged 35 to 65 years, who previously participated in our Family Healthware study and had a moderate or strong familial risk for any of the 6 diseases were subsequently reviewed. The main outcome measures were PCP response to the prompts, adding family history risk to problem summary lists, and patient screening status for each disease.\nThe 492 eligible patients had 847 visits during the study period; 152 visits had no documentation of response to a family history prompt. Of the remaining 695 visits, physician responses were reviewed family history (n = 372, 53.5%), discussed family history (n = 159, 22.9%), not addressed (n = 155, 22.3%), and reviewed family history and ordered tests/referrals (n = 5, 0.7%). There was no significant change in problem summary list documentation of risk status or screening interventions for any of the 6 diseases.\"\nQuestion:\n\"Prompting Primary Care Providers about Increased Patient Risk As a Result of Family History: Does It Work?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "22694248": {
                "source": [
                    "\"Although the retroperitoneal approach has been the preferred choice for open urological procedures, retroperitoneoscopy is not the preferred approach for laparoscopy. This study aims to develop a training model for retroperitoneoscopy and to establish an experimental learning curve.\nFifteen piglets were operated on to develop a standard retroperitoneoscopic nephrectomy (RPN) training model. All procedures were performed with three ports. Intraoperative data (side, operative time, blood loss, peritoneal opening) were recorded. Animals were divided into groups A, the first eight, and B, the last seven cases. Data were statistically analyzed.\nWe performed fifteen RPNs. The operative time varied from 15 to 50 minutes (median 30 minutes). Blood loss varied from 5 to 100 mL (median 20 mL). We experienced five peritoneal openings; we had two surgical vascular complications managed laparoscopically. There was statistical difference between groups A and B for peritoneal opening (p = 0.025), operative time (p = 0.0037), and blood loss (p = 0.026).\nRPN in a porcine model could simulate the whole procedure, from creating the space to nephrectomy completion. Experimental learning curve was eight cases, after statistical data analysis.\"\nQuestion:\n\"Is there a model to teach and practice retroperitoneoscopic nephrectomy?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26348845": {
                "source": [
                    "\"Rapid prescreening (RPS) is one of the quality assurance (QA) methods used in gynecologic cytology. The efficacy of RPS has been previously studied but mostly with respect to squamous lesions; in fact, there has been no study so far specifically looking at the sensitivity of RPS for detecting glandular cell abnormalities.\nA total of 80,565 Papanicolaou (Pap) smears underwent RPS during a 25-month period. A sample was designated as \"review for abnormality\" (R) if any abnormal cells (at the threshold of atypical squamous cells of undetermined significance/atypical glandular cells [AGC]) were thought to be present or was designated as negative (N) if none were detected. Each sample then underwent full screening (FS) and was designated as either R or N and also given a cytologic interpretation.\nThe final cytologic interpretation was a glandular cell abnormality (\u2265AGC) in 107 samples (0.13%); 39 of these (36.4%) were flagged as R on RPS. Twenty-four patients (33.8%) out of 71 who had histologic follow-up were found to harbor a high-grade squamous intraepithelial lesion or carcinoma; 13 of those 24 Pap smears (54.2%) had been flagged as R on RPS. Notably, 11 AGC cases were picked up by RPS only and not by FS and represented false-negative cases; 2 of these showed endometrial adenocarcinoma on histologic follow-up.\"\nQuestion:\n\"Pap smears with glandular cell abnormalities: Are they detected by rapid prescreening?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "9100537": {
                "source": [
                    "\"Cytologic criteria reported to be helpful in the distinction of proliferative breast disease without atypia (PBD) from nonproliferative breast disease (NPBD) have not been rigorously tested.\nFifty-one air-dried, Diff-Quik-stained fine-needle aspirates (FNA) of palpable breast lesions with biopsy-proven diagnoses of NPBD (34 cases) or PBD (17 cases) were reviewed. The smears were evaluated for the cellularity, size, and architectural arrangement of the epithelial groups; the presence of single epithelial cells and myoepithelial cells; and nuclear characteristics.\nThe only cytologic feature found to be significantly different between PBD and NPBD was a swirling pattern of epithelial cells. A swirling pattern was noted in 13 of 17 PBD cases (76%) and 12 of 34 NPBD cases (35%) (P = 0.008).\"\nQuestion:\n\"Can nonproliferative breast disease and proliferative breast disease without atypia be distinguished by fine-needle aspiration cytology?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "26418441": {
                "source": [
                    "\"Polyps identified at colonoscopy are predominantly diminutive (<5\u2009mm) with a small risk (>1%) of high-grade dysplasia or carcinoma; however, the cost of histological assessment is substantial.AIM: The aim of this study was to determine whether prediction of colonoscopy surveillance intervals based on real-time endoscopic assessment of polyp histology is accurate and cost effective.\nA prospective cohort study was conducted across a tertiary care and private community hospital. Ninety-four patients underwent colonoscopy and polypectomy of diminutive (\u22645\u2009mm) polyps from October 2012 to July 2013, yielding a total of 159 polyps. Polyps were examined and classified according to the Sano-Emura classification system. The endoscopic assessment (optical diagnosis) of polyp histology was used to predict appropriate colonoscopy surveillance intervals. The main outcome measure was the accuracy of optical diagnosis of diminutive colonic polyps against the gold standard of histological assessment.\nOptical diagnosis was correct in 105/108 (97.2%) adenomas. This yielded a sensitivity, specificity and positive and negative predictive values (with 95%CI) of 97.2% (92.1-99.4%), 78.4% (64.7-88.7%), 90.5% (83.7-95.2%) and 93% (80.9-98.5%) respectively. Ninety-two (98%) patients were correctly triaged to their repeat surveillance colonoscopy. Based on these findings, a cut and discard approach would have resulted in a saving of $319.77 per patient.\"\nQuestion:\n\"Can we ease the financial burden of colonoscopy?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "15381614": {
                "source": [
                    "\"Cutaneous melanoma in nonwhite persons has a manifestation and a prognosis that are different than those of cutaneous melanoma in white persons.\nCase series.\nTertiary care university-affiliated community medical center located in a multiethnic state in which white persons are a minority of the population.\nConsecutive series of 357 patients with melanoma seen between January 1994 and August 2003.\nEthnicity, age, sex, primary site, tumor thickness, nodal status, stage at diagnosis, and survival.\nThere were 208 men and 149 women who ranged in age from 15 to 93 years (mean, 58 years). Twenty-two patients initially had unknown primary sites. Of these 357 patients, 67 (18.7%) were nonwhite. There was no statistically significant difference in the age (P =.10) or sex (P =.57) distribution of these 2 populations. Nonwhite patients at initial diagnosis had thicker tumors (P =.002), more frequently had ulcerated primary tumors (P<.001), more frequently had positive nodes (P =.004), and were at a more advanced stage (P =.002) than their white counterparts. The anatomic distribution between the 2 populations was significantly different (P<.001), with a high incidence of melanoma on the sole and subungual locations and a substantially less frequent occurrence on the head and neck, trunk, and extremities in the nonwhite population when compared with the white population. The overall survival rate of the nonwhite patients was significantly worse than that of the white patients, but when stratified by stage at initial diagnosis, there was no difference in outcome.\"\nQuestion:\n\"Cutaneous melanoma in a multiethnic population: is this a different disease?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "9363244": {
                "source": [
                    "\"To determine the effect of occupational exposure in a nuclear power plant in Griefswald, Germany on male and female fecundity.\nThe frequency of men and women exposed to ionizing radiation through work in a nuclear power plant among 270 infertile couples was retrospectively compared to a control fertile population using a pair-matched analysis. The total cumulative equivalent radiation dose was determined. In addition, the spermiograms of the male partners in both groups were compared and correlated to the degree of exposure.\nNo differences were noted in the frequency of nuclear power plant exposure between sterile and fertile groups. There was a higher rate of anomalous spermiograms in nuclear power plant workers. However, abnormalities were temporary. No correlation was found between the cumulative equivalent radiation dose and abnormal spermiograms.\"\nQuestion:\n\"Does occupational nuclear power plant radiation affect conception and pregnancy?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "23677366": {
                "source": [
                    "\"Anteroposterior, lateral, and right and left oblique lumbar spine radiographs are often a standard part of the evaluation of children who are clinically suspected of having spondylolysis. Recent concerns regarding radiation exposure and costs have brought the value of oblique radiographs into question. The purpose of the present study was to determine the diagnostic value of oblique views in the diagnosis of spondylolysis.\nRadiographs of fifty adolescents with L5 spondylolysis without spondylolisthesis and fifty controls were retrospectively reviewed. All controls were confirmed not to have spondylolysis on the basis of computed tomographic scanning, magnetic resonance imaging, or bone scanning. Anteroposterior, lateral, and right and left oblique radiographs of the lumbar spine were arranged into two sets of slides: one showing four views (anteroposterior, lateral, right oblique, and left oblique) and one showing two views (anteroposterior and lateral only). The slides were randomly presented to four pediatric spine surgeons for diagnosis, with four-view slides being presented first, followed by two-view slides. The slides for twenty random patients were later reanalyzed in order to calculate of intra-rater agreement. A power analysis demonstrated that this study was adequately powered. Inter-rater and intra-rater agreement were assessed on the basis of the percentage of overall agreement and intraclass correlation coefficients (ICCs). PCXMC software was used to generate effective radiation doses. Study charges were determined from radiology billing data.\nThere was no significant difference in sensitivity and specificity between four-view and two-view radiographs in the diagnosis of spondylolysis. The sensitivity was 0.59 for two-view studies and 0.53 for four-view studies (p = 0.33). The specificity was 0.96 for two-view studies and 0.94 for four-view studies (p = 0.60). Inter-rater agreement, intra-rater agreement, and agreement with gold-standard ICC values were in the moderate range and also demonstrated no significant differences. Percent overall agreement was 78% for four-view studies and 82% for two-view studies. The radiation effective dose was 1.26 mSv for four-view studies and 0.72 mSv for two-view studies (difference, 0.54 mSv). The charge for four-view studies was $145 more than that for two-view studies.\"\nQuestion:\n\"Do oblique views add value in the diagnosis of spondylolysis in adolescents?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "15703931": {
                "source": [
                    "\"Compared with computed tomography (CT) and magnetic resonance imaging (MRI), positron emission tomography (PET) may have additional value in the assessment of primary and recurrent cervical cancer. However, the degree of tumour uptake of (18)F-2-fluoro-2-deoxy-D: -glucose (FDG) uptake is sometimes influenced by diabetes mellitus (DM). Therefore, we conducted this prospective study to compare the diagnostic ability of FDG-PET in patients with cervical cancer complicated by DM and those without DM.\nPatients with untreated locally advanced primary or clinically curable recurrent cervical carcinoma were enrolled. Both FDG-PET and MRI/CT scans were performed within 2 weeks. Patients were categorised into the following groups: hyperglycaemic DM (fasting blood sugar>126 mg/dl), euglycaemic DM and non-DM. The lesions were confirmed histologically or by clinical follow-up. The receiver operating characteristic curve method, with calculation of the area under the curve (AUC), was used to evaluate the discriminative power.\nFrom February 2001 to January 2003, 219 patients (75 with primary and 144 with recurrent cervical cancer) were eligible for analysis. Sixteen had hyperglycaemic DM, 12 had euglycaemic DM and 191 were in the non-DM group. The diagnostic power of PET in the hyperglycaemic DM, euglycaemic DM and non-DM groups did not differ significantly with regard to the identification of either metastatic lesions (AUC, 0.967/0.947/0.925, P>0.05) or primary tumours/local recurrence (AUC, 0.950/0.938/0.979, P>0.05). Considering all DM patients, PET showed a significantly higher detection power than MRI/CT scans in respect of metastatic lesions (AUC=0.956 vs 0.824, P=0.012).\"\nQuestion:\n\"Does diabetes mellitus influence the efficacy of FDG-PET in the diagnosis of cervical cancer?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "23831910": {
                "source": [
                    "\"From March 2007 to January 2011, 88 DBE procedures were performed on 66 patients. Indications included evaluation anemia/gastrointestinal bleed, small bowel IBD and dilation of strictures. Video-capsule endoscopy (VCE) was used prior to DBE in 43 of the 66 patients prior to DBE evaluation.\nThe mean age was 62 years. Thirty-two patients were female, 15 were African-American; 44 antegrade and 44 retrograde DBEs were performed. The mean time per antegrade DBE was 107.4\u00b130.0 minutes with a distance of 318.4\u00b1152.9 cm reached past the pylorus. The mean time per lower DBE was 100.7\u00b127.3 minutes with 168.9\u00b1109.1 cm meters past the ileocecal valve reached. Endoscopic therapy in the form of electrocautery to ablate bleeding sources was performed in 20 patients (30.3%), biopsy in 17 patients (25.8%) and dilation of Crohn's-related small bowel strictures in 4 (6.1%). 43 VCEs with pathology noted were performed prior to DBE, with findings endoscopically confirmed in 32 cases (74.4%). In 3 cases the DBE showed findings not noted on VCE.\"\nQuestion:\n\"Double balloon enteroscopy: is it efficacious and safe in a community setting?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "20530150": {
                "source": [
                    "\"Children referred with symptomatic gallstones complicating HS between April 1999 and April 2009 were prospectively identified and reviewed retrospectively. During this period, the policy was to undertake concomitant splenectomy only if indicated for haematological reasons and not simply because of planned cholecystectomy.\nA total of 16 patients (mean age 10.4, range 3.7 to 16 years, 11 women) with HS and symptomatic gallstones underwent cholecystectomy. Three patients subsequently required a splenectomy for haematological reasons 0.8-2.5 years after cholecystectomy; all three splenectomies were performed laparoscopically. There were no postoperative complications in the 16 patients; postoperative hospital stay was 1-3 days after either cholecystectomy or splenectomy. The 13 children with a retained spleen remain under regular review by a haematologist (median follow-up 4.6, range 0.5 to 10.6 years) and are well and transfusion independent.\"\nQuestion:\n\"Is cholecystectomy really an indication for concomitant splenectomy in mild hereditary spherocytosis?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "12442934": {
                "source": [
                    "\"To determine whether prior exposure of non-steroidal anti-inflammatory drugs increases perioperative blood loss associated with major orthopaedic surgery.\nFifty patients scheduled for total hip replacement were allocated to two groups (double blind, randomized manner). All patients were pretreated for 2 weeks before surgery: Group 1 with placebo drug, Group 2 with ibuprofen. All patients were injected intrathecally with bupivacaine 20mg plus morphine 0.1 mg, in a total volume of 4 mL, to provide surgical anaesthesia.\nThe presence of severe adverse effects caused eight patients in the ibuprofen group and six in the placebo group to terminate their participation in the trial. The perioperative blood loss increased by 45% in the ibuprofen group compared with placebo. The total (+/-SD) blood loss in the ibuprofen group was 1161 (+/-472) mL versus 796 (+/-337) mL in the placebo group.\"\nQuestion:\n\"Does ibuprofen increase perioperative blood loss during hip arthroplasty?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "27184293": {
                "source": [
                    "\"Microbial contamination can be a marker for faulty process and is assumed to play an important role in the collection of hematopoietic progenitor cell (HPC) and infusion procedure. We aimed to determine the microbial contamination rates and evaluate the success of hematopoietic cell transplantation (HCT) in patients who received contaminated products.PATIENTS-\nWe analyzed microbial contamination records of HPC grafts between 2012 and 2015, retrospectively. Contamination rates of autologous donors were evaluated for at three steps: at the end of mobilization, following processing with dimethyl sulfoxide, and just before stem cell infusion. Grafts of allogeneic donors were assessed only before HCT.\nA total of 445 mobilization procedures were carried out on 333 (167 autologous and 166 allogeneic) donors. The microbiological contamination of peripheral blood (323/333 donations) and bone marrow (10/333 donations) products were analyzed. Bacterial contamination was detected in 18 of 1552 (1.15 %) culture bottles of 333 donors. During the study period 248 patients underwent HCT and among these patients microbial contamination rate on sample basis was 1.3 % (16/1212). Microbial contamination detected in nine patients (7 autologous; 2 allogeneic). In 8 of 9 patients, a febrile neutropenic attack was observed. The median day for the neutropenic fever was 4 days (0-9). None of the patients died within the post-transplant 30 days who received contaminated products.\"\nQuestion:\n\"Does microbial contamination influence the success of the hematopoietic cell transplantation outcomes?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "23506394": {
                "source": [
                    "\"Arterial calcification is a significant cardiovascular risk factor in hemodialysis patients. A series of factors are involved in the process of arterial calcification; however, the relationship between malnutrition and arterial calcification is still unclear.\n68 hemodialysis patients were enrolled in this study. Nutrition status was evaluated using modified quantitative subjective global assessment (MQSGA). Related serum biochemical parameters were measured. And the radial artery samples were collected during the arteriovenous fistula surgeries. Hematoxylin/eosin stain was used to observe the arterial structures while Alizarin red stain to observe calcified depositions and classify calcified degree. The expressions of bone morphogenetic protein 2 (BMP2) and matrix Gla protein (MGP) were detected by immunohistochemistry and western blot methods.\n66.18% hemodialysis patients were malnutrition. In hemodialysis patients, the calcified depositions were mainly located in the medial layer of the radial arteries and the expressions of BMP2 and MGP were both increased in the calcified areas. The levels of serum albumin were negatively associated with calcification score and the expressions of BMP2 and MGP. While MQSGA score, serum phosphorus and calcium\u2009\u00d7\u2009phosphorus product showed positive relationships with calcification score and the expressions of BMP2 and MGP.\"\nQuestion:\n\"Malnutrition, a new inducer for arterial calcification in hemodialysis patients?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "17916877": {
                "source": [
                    "\"To determine the therapeutic effect (alleviation of vascular type headache) and side effects of a slow intravenous metoclopramide infusion over 15 min compared with those effects of a bolus intravenous metoclopramide infusion over 2 min in the treatment of patients with recent onset vascular type headache.\nAll adults treated with metoclopramide for vascular type headache were eligible for entry into this clinical randomised double blinded trial. This study compared the effects of two different rates of intravenous infusion of metoclopramide over a period of 13 months at a university hospital emergency department. During the trial, side effects and headache scores were recorded at baseline (0 min), and then at 5, 15, 30 and 60 min. Repeated measures analysis of variance was used to compare the medication's efficacy and side effects.\nA total of 120 patients presenting to the emergency department met the inclusion criteria. Of these, 62 patients (51.7%) were given 10 mg metoclopramide as a slow intravenous infusion over 15 min (SIG group) and 58 patients (48.3%) were given 10 mg metoclopramide intravenous bolus infusion over 2 min (BIG group). 17 of the 58 patients in the BIG group (29.3%) and 4 of the 62 patients (6.5%) in the SIG group had akathisia (p = 0.001). There were no significant differences between the BIG and SIG groups in terms of mean headache scores (p = 0.34) and no adverse reactions in the study period. Metoclopramide successfully relieved the headache symptom(s) of patients in both the BIG and SIG groups.\"\nQuestion:\n\"Intravenous administration of metoclopramide by 2 min bolus vs 15 min infusion: does it affect the improvement of headache while reducing the side effects?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "12630042": {
                "source": [
                    "\"The long-term survival of patients with gastric cancer is governed by various factors, such as the clinical stage of the cancer, the patient's nutritional state, and the treatment and may be governed by the volume of intraperitoneal adipose tissue. The aim of this study is to clarify the relationship between the degree of the patients' body mass index and their long-term survival.\nGastric cancer patients who had undergone a gastrectomy with D2-lymphadenectomy and with resection A and B according to the criteria of the Japanese Research Society for Gastric Cancer Rules were subgrouped into those patients with a body mass index<0.185 (the lower body mass index group) and those patients with a body mass index>0.210 (the higher body mass index group). The patient's morbidity and long-term survival rate was retrospectively compared between the 2 groups.\nA significantly longer mean survival rate was observed for the lower body mass index group in stage 2 (1667 vs. 1322 days, P = 0.0240). Also, a significantly longer mean survival rate was observed for the higher BMI group in stage 3a (1431 vs. 943, P = 0.0071).\"\nQuestion:\n\"Does body mass index (BMI) influence morbidity and long-term survival in gastric cancer patients after gastrectomy?\""
                ],
                "target": "maybe",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "10759659": {
                "source": [
                    "\"To compare the accuracy achieved by a trained urology nurse practitioner (UNP) and consultant urologist in detecting bladder tumours during flexible cystoscopy.\nEighty-three patients underwent flexible cystoscopy by both the UNP and consultant urologist, each unaware of the other's findings. Before comparing the findings, each declared whether there was tumour or any suspicious lesion requiring biopsy.\nOf 83 patients examined by flexible cystoscopy, 26 were found to have a tumour or a suspicious lesion. One tumour was missed by the UNP and one by the urologist; each tumour was minute. Analysis using the chance-corrected proportional agreement (Kappa) was 0.94, indicating very close agreement.\"\nQuestion:\n\"The nurse cystoscopist: a feasible option?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "9569972": {
                "source": [
                    "\"To investigate whether the S + G2/M fraction (proliferative index) is a prognostic determinant in breast cancers classified as Auer IV.\nPrognostic evaluation of Auer IV DNA histograms with respect to the high versus low S + G2/M fraction, obtained by image cytometry on consecutive breast cancer imprint preparations.\nWhen studying recurrence-free survival (n = 136), the prognostic value of S + G2/M was found to vary with time: it was negligible before the median time to relapse (1.5 years) but thereafter statistically significant, in both univariate and multivariate analysis. The same pattern was found when overall survival was used as the end point; the effect was delayed to about the median time until death (three years). Tumors with a low S + G2/M fraction were smaller and more often estrogen receptor- and progesterone receptor-positive than those with a high S + G2/M fraction.\"\nQuestion:\n\"Proliferative index obtained by DNA image cytometry. Does it add prognostic information in Auer IV breast cancer?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "25891436": {
                "source": [
                    "\"Previous studies have reported that the total bilirubin (TB) level is associated with coronary artery disease, heart failure and atrial fibrillation. These heart diseases can produce cardiogenic cerebral embolism and cause cardioembolic stroke. However, whether the serum TB could be a biomarker to differentiate cardioembolic stroke from other stroke subtypes is unclear.\nOur study consisted of 628 consecutive patients with ischaemic stroke. Various clinical and laboratory variables of the patients were analysed according to serum TB quartiles and stroke subtypes.\nThe higher TB quartile group was associated with atrial fibrillation, larger left atrium diameter, lower left ventricular fractional shortening and cardioembolic stroke (P<0.001, P = 0.001, P = 0.033, P<0.001, respectively). Furthermore, serum TB was a statistically significant independent predictor of cardioembolic stroke in a multivariable setting (Continuous, per unit increase OR = 1.091, 95%CI: 1.023-1.164, P = 0.008).\"\nQuestion:\n\"Is serum total bilirubin useful to differentiate cardioembolic stroke from other stroke subtypes?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "10411439": {
                "source": [
                    "\"Lower limb compartment syndrome has been reported to occur after colorectal, urological, and gynecological procedures during which the patient's lower limbs are elevated for prolonged periods of time.\nWe investigated lower limb perfusion in a group of patients undergoing prolonged pelvic surgery both during and immediately after surgery, using intra-arterial blood pressure monitoring, laser doppler flowmetry, and pulse oximetry.\nUse of the modified lithotomy position was not associated with any demonstrable decrease in lower limb perfusion. The addition of 15 degrees head-down tilt, however, during pelvic dissection, led to an immediate and significant drop in lower limb perfusion (P<0.05; Mann-Whitney U test). The subgroup of patients analyzed postoperatively showed a ten-fold increase (P<0.01) in perfusion that was confined to the muscle compartment with no demonstrable increase in skin perfusion or intra-arterial pedal blood pressure.\"\nQuestion:\n\"Lloyd-Davies position with Trendelenburg--a disaster waiting to happen?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "21228436": {
                "source": [
                    "\"The purpose of this study was to evaluate the impact of a patient-safety curriculum administered during a paediatric clerkship on medical students' attitudes towards patient safety.\nMedical students viewed an online video introducing them to systems-based analyses of medical errors. Faculty presented an example of a medication administration error and demonstrated use of the Learning From Defects tool to investigate the defect. Student groups identified and then analysed medication errors during their clinical rotation using the Learning From Defects framework to organise and present their findings. Outcomes included patient safety attitudinal changes, as measured by questions derived from the Safety Attitudes Questionnaire.\n108 students completed the curriculum between July 2008 and July 2009. All student groups (25 total) identified, analysed and presented patient safety concerns. Curriculum effectiveness was demonstrated by significant changes on questionnaire items related to patient safety attitudes. The majority of students felt that the curriculum was relevant to their clinical rotation and should remain part of the clerkship.\"\nQuestion:\n\"Can teaching medical students to investigate medication errors change their attitudes towards patient safety?\""
                ],
                "target": "yes",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "22349635": {
                "source": [
                    "\"Treatment of elderly cancer patients has gained importance. One question regarding the treatment of metastatic spinal cord compression (MSCC) is whether elderly patients benefit from surgery in addition to radiotherapy? In attempting to answer this question, we performed a matched-pair analysis comparing surgery followed by radiotherapy to radiotherapy alone.\nData from 42 elderly (age>\u200965 years) patients receiving surgery plus radiotherapy (S\u2009+\u2009RT) were matched to 84 patients (1:2) receiving radiotherapy alone (RT). Groups were matched for ten potential prognostic factors and compared regarding motor function, local control, and survival. Additional matched-pair analyses were performed for the subgroups of patients receiving direct decompressive surgery plus stabilization of involved vertebrae (DDSS, n\u2009=\u200981) and receiving laminectomy (LE, n\u2009=\u200945).\nImprovement of motor function occurred in 21% after S\u2009+\u2009RT and 24% after RT (p\u2009=\u20090.39). The 1-year local control rates were 81% and 91% (p\u2009=\u20090.44), while the 1-year survival rates were 46% and 39% (p\u2009=\u20090.71). In the matched-pair analysis of patients receiving DDSS, improvement of motor function occurred in 22% after DDSS\u2009+\u2009RT and 24% after RT alone (p\u2009=\u20090.92). The 1-year local control rates were 95% and 89% (p\u2009=\u20090.62), and the 1-year survival rates were 54% and 43% (p\u2009=\u20090.30). In the matched-pair analysis of patients receiving LE, improvement of motor function occurred in 20% after LE\u2009+\u2009RT and 23% after RT alone (p\u2009=\u20090.06). The 1-year local control rates were 50% and 92% (p\u2009=\u20090.33). The 1-year survival rates were 32% and 32% (p\u2009=\u20090.55).\"\nQuestion:\n\"Do elderly patients benefit from surgery in addition to radiotherapy for treatment of metastatic spinal cord compression?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            },
            "22251324": {
                "source": [
                    "\"This study investigated associations between the performance of dental students in each of the three components of the selection procedure [academic average, Undergraduate Medicine and Health Sciences Admission Test (UMAT) and structured interview], socio-demographic characteristics and their academic success in an undergraduate dental surgery programme.\nLongitudinal review of admissions data relating to students entering dental education at the University of Otago, New Zealand, between 2004 and 2009 was compared with academic performance throughout the dental programme.\nAfter controlling for variables, pre-admission academic average, UMAT scores and interview performance did not predict performance as a dental student. Class place in second year, however, was a strong predictor of class place in final year. Multivariate analysis demonstrated that the best predictors of higher class placement in the final year were New Zealand European ethnicity and domestic (rather than international) student status. Other socio-demographic characteristics were not associated with performance. These interim findings provide a sound base for the ongoing study.\"\nQuestion:\n\"Does performance in selection processes predict performance as a dental student?\""
                ],
                "target": "no",
                "list_label": [
                    "yes",
                    "no",
                    "maybe"
                ],
                "config": "none",
                "task": "pubmed_qa",
                "prompt": "pubmed_qa"
            }
        }
    }
}